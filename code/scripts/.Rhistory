}
distribution<-Run()
table <-table(distribution)
sort(table, decreasing = TRUE)
table <- sort(table, decreasing = TRUE)
table <- data.frame(table)
table
library(dplyr)
?left_join
names(table)
colnames(table)
colnames(table) <- c("spacenum", "frequency")
ncol(table)
table <-table(distribution)
as.tbl(table)
table <- sort(table, decreasing = TRUE)
table <- data.frame(table)
as.tbl(table)
table
colnames(table) <- c("frequency")
table
qnorm(0.289,0,1)
pnorm(0.289,0,1)
w = rnorm(n = 100, mean = 0, sd = 1)
set.seed(200)
w = rnorm(n = 100, mean = 0, sd = 1)
w
v = filter (w, sides = 2, rep(1/3,3))
v
plot.ts(w, main= 'white noise')
?filter
plot.ts(v, main= 'movin average')
par( mfrow = c(1,3))
plot.ts(w, main= 'white noise')
plot.ts(v, main= 'movin average')
plot.ts(w, main= 'white noise')
lines(v, col='red')
par(mfrow = c(1,2))
acf(w)
acf(na.omit(v))
plot(test)
test = na.omit(v)
plot(test[1])
plot(test)
par(mfrow = c(1,3))
wd = w + 0.05
xd = cumsum(wd)
par(mfrow = c(1,3))
plot.ts(xd, ylim = range(c(x,xd)), main = 'random walk')
plot.ts(xd, ylim = range(c(x,xd)), main = 'random walk')
x = cumsum(w)
x = cumsum(w)
plot.ts(xd, ylim = range(c(x,xd)), main = 'random walk')
lines(x, col = 'red')
acf(xd)
acf(x)
install.packages('quantmod')
library(quantmod)
display(FB)
plot(FB)
mal = arima.sim(list(order = c(0,0,1), ma=0.9), n=100)
plot(mal)
par(mfrow = c(1,2))
plot(ma1)
plot(acf(ma1))
par(mfrow = c(1,2))
plot(mal)
plot(acf(mal))
acf(mal)
test(acf(mal))
0.9 / (1 + 0.9^2)
test = (acf(mal))
test
plot(ma1)
mal = arima.sim(list(order = c(0,0,1), ma=-0.9), n = 100)
plot(ma1)
plot(mal)
plot(mal)
plot(acf(mal))
plot(mal)
plot(acf(mal))
par(mfrow = c(1,1))
plot(mal)
plot(acf(mal))
arl = arima.sim(list(order= c(1,0,0), dr= 0.9), n =100)
arl = arima.sim(list(order= c(1,0,0), ar= 0.9), n =100)
plot(arl)
acf(arl)
test = acf(arl, plot = F)
test
0.9 * (0:20)
0.9 ^ (0:20)
arl = arima.sim(list(order= c(1,0,0), ar= -0.9), n =100)
plot(arl)
acf(arl)
test = acf(arl, plot = F)
arma22 = arima.sim(list(order = c(2,0,2), ar = (1/3, 1/4), ma = (-1/3, 1/4)),n = 100)
arma22 = arima.sim(list(order = c(2,0,2), ar = (1/3,1/4), ma = (-1/3,1/4)),n = 100)
arma22 = arima.sim(list(order = c(2,0,2), ar = c(1/3, 1/4), ma = c(-1/3, 1/4)), n = 100)
plot(arma22)
acf(arma22)
getwd()
setwd("Users/Desktop/fall 2016/stats 153")
setwd("Desktop/fall 2016/stats 153")
load('stat153_zillow.Rdata')
age = stat153$ageofinventory_public
age
View(age)
View(check)
age = age[1:53]
install.packages('xts')
age = age[1:53,]
library(xts)
age_ts = xts(age$index, age$date)
plot(age_ts)
acf(age_ts)
summary(lmod)
lmod = lm(age_tx ~ time(age_ts))
summary(lmod)
lmod = lm(age_ts ~ time(age_ts))
summary(lmod)
plot(age_ts)
abline(lmod)
abline(lmod)
abline(lmod.fit)
lmod = lm(age_ts ~ time(age_ts))
summary(lmod)
plot(age_ts)
abline(lmod)
age_ts2 = ts(age$index)
age_ts2
plot(age_ts2)
lmod = lm(age_ts2~time(age_ts2))
abline(lmod)
plot(resid(lmod))
plot(resid(lmod), type = 'l')
plot(diff(age_ts2))
plot(1)
par(mfrow = c(1,2))
plot(age_ts2)
plot(diff(age_ts2))
install.packages('astsa')
lag.plot(age_ts2,1)
estimate2 <- function(n, phi1, phi2){
data = arima.sim(n=n, list(ma = c(phi1, phi2)))
MA2mod = arima(data, order = c(0,0,2), method ='ml') #fits AR(1) according to Yule-Walker
ephi1 = MA2mod$coef[1] #get the coefficient
ephi2 = MA2mod$coef[2]
if (length(ephi1) == 0){
return (c(0,ephi2))
}
if (length(ephi2) == 0){
return (c(ephi1,0))
}
return (c(ephi1, ephi2))
}
replicate(10, estimate2(size, params1, params2))
replicate(10, estimate2(60, 1.5, 0.75))
estimate2(60, 1.5, 0.75)
arima.sim(60, list(ma = c(1.5, 0.75)))
?arima.sim
arima.sim(list(order = c(0,0,2), ma = c(1.5, 0.75)), n = 60)
estimate2 <- function(n, phi1, phi2){
data = arima.sim(list(order = c(0,0,2), ma = c(phi1, phi2)), n = n)
MA2mod = arima(data, order = c(0,0,2), method ='ml') #fits AR(1) according to Yule-Walker
ephi1 = MA2mod$coef[1] #get the coefficient
ephi2 = MA2mod$coef[2]
if (length(ephi1) == 0){
return (c(0,ephi2))
}
if (length(ephi2) == 0){
return (c(ephi1,0))
}
return (c(ephi1, ephi2))
}
replicate(100, estimate2(60, 1.5, 0.75))
estimate2(60, 1.5, 0.75)
data = arima.sim(list(order = c(0,0,2), ma = c(1.5, 0.75)), n = 60)
arima(data, order = c(0,0,2), method ='ml')
estimate2 <- function(n, phi1, phi2){
data = arima.sim(list(order = c(0,0,2), ma = c(phi1, phi2)), n = n)
MA2mod = arima(data, order = c(0,0,2), method ='ml') #fits AR(1) according to Yule-Walker
ephi1 = MA2mod$coef[1] #get the coefficient
ephi2 = MA2mod$coef[2]
if (length(ephi1) == 0){
return (c(0,ephi2))
}
if (length(ephi2) == 0){
return (c(ephi1,0))
}
return (c(ephi1, ephi2))
}
find_mean_variance <- function(size, params1, params2){
allphis = replicate(10000, estimate2(size, params1, params2))
avgphi = mean(allphis)
varphi = var(allphis)
cat('The average and variance phi for the model n=', size, 'and phi=', params, 'is \n', toString(c(avgphi, varphi)),'\n')
}
estimate2 <- function(n, phi1, phi2){
data = arima.sim(list(order = c(0,0,2), ma = c(phi1, phi2)), n = n)
MA2mod = arima(data, order = c(0,0,2), method ='ml') #fits AR(1) according to Yule-Walker
ephi1 = MA2mod$coef[1] #get the coefficient
ephi2 = MA2mod$coef[2]
if (length(ephi1) == 0){
return (c(0,ephi2))
}
if (length(ephi2) == 0){
return (c(ephi1,0))
}
return (c(ephi1, ephi2))
}
estimate2(100,0.95, 0)
estimate2 <- function(n, phi1, phi2){
data = arima.sim(list(order = c(0,0,2), ma = c(phi1, phi2)), n = n)
MA2mod = arima(data, order = c(0,0,2), method ='ML') #fits AR(1) according to Yule-Walker
ephi1 = MA2mod$coef[1] #get the coefficient
ephi2 = MA2mod$coef[2]
if (length(ephi1) == 0){
return (c(0,ephi2))
}
if (length(ephi2) == 0){
return (c(ephi1,0))
}
return (c(ephi1, ephi2))
}
estimate2(100,0.95, 0)
replicate(estimate2(100,0.95, 0))
replicate(10,estimate2(100,0.95, 0))
allphis = replicate(10,estimate2(100,0.95, 0))
allphis[1,]
find_mean_variance <- function(size, params1, params2){
allphis = replicate(100, estimate2(size, params1, params2))
avgphi1 = mean(allphis[1,])
avgphi2 = mean(allphis[2,])
varphi1 = var(allphis[1,])
varphi2 = var(allphis[2,])
cov1 = cov(allphis[1,], allphis[2,])
cat('The average and variance phi for the model n=', size, 'and phi=', params, 'is \n', toString(c(avgphi, varphi)),'\n')
}
find_mean_variance(60,0.95,0)
find_mean_variance <- function(size, params1, params2){
allphis = replicate(100, estimate2(size, params1, params2))
avgphi1 = mean(allphis[1,])
avgphi2 = mean(allphis[2,])
varphi1 = var(allphis[1,])
varphi2 = var(allphis[2,])
cov1 = cov(allphis[1,], allphis[2,])
}
find_mean_variance(60,0.95,0)
avgphi2
a = find_mean_variance(60,0.95,0)
source('~/Desktop/fall 2016/Stats 153/week10.R', echo=TRUE)
find_mean_variance1 <- function(size, params1, params2){
allphis = replicate(100, estimate2(size, params1, params2))
avgphi1 = mean(allphis[1,])
avgphi2 = mean(allphis[2,])
varphi1 = var(allphis[1,])
varphi2 = var(allphis[2,])
cov1 = cov(allphis[1,], allphis[2,])
print(c(avgphi1, avgphi2, varphi1, varphi2))
cat("\n")
print(cov1)
}
find_mean_variance1(100, 0.95, 0)
find_mean_variance1(100, 0.95, 0.3)
setwd('/Users/zhonglingjiang/stats_159/stat159-project2/code/scripts/')
scaled_credit <- read.csv("../../data/scaled_credit.csv", stringsAsFactors=FALSE)
load("../../data/training_and_testing.RData")
grid = 10^seq(10, -2, length = 100)
lasso_cv = cv.glmnet(as.matrix(x_training), as.matrix(y_training), alpha=1, intercept = FALSE, lambda = grid,
standardize = FALSE)
library(glmnet)
lasso_cv = cv.glmnet(as.matrix(x_training), as.matrix(y_training), alpha=1, intercept = FALSE, lambda = grid,
standardize = FALSE)
best_lambda = lasso_cv$lambda.min
load("../../data/training_and_testing.RData")
lasso_cv = cv.glmnet(as.matrix(x_training), as.matrix(y_training), alpha=1, intercept = FALSE, lambda = grid,
standardize = FALSE)
save(training_set, testing_set, x_training, y_training, x_testing, y_testing, file = '../../data/training_and_testing.RData')
#read in the scaled data
scaled_credit = read.csv("../../data/scaled_credit.csv", stringsAsFactors=FALSE)
#split into training and testing set
set.seed(200)
sample_size = 300
sample = sample(1:dim(scaled_credit)[1], sample_size, replace = FALSE)
training_set = scaled_credit[sample,]
testing_set = scaled_credit[-sample,]
#Setting Training and Testing Vectors
x_training = training_set[ ,-12]
y_training = training_set[ ,12]
x_testing = testing_set[ ,-12]
y_testing = testing_set[ ,12]
#Storing these vectors into RData
save(training_set, testing_set, x_training, y_training, x_testing, y_testing, file = '../../data/training_and_testing.RData')
load("../../data/training_and_testing.RData")
lasso_cv = cv.glmnet(as.matrix(x_training), as.matrix(y_training), alpha=1, intercept = FALSE, lambda = grid,
standardize = FALSE)
lasso_cv
lasso_cv$lambda.min
lasso_mse <- function(best_lambda){
scaled_credit <- read.csv("../../data/scaled_credit.csv", stringsAsFactors=FALSE)
load("../../data/training_and_testing.RData")
grid = 10^seq(10, -2, length = 100)
lasso_cv = cv.glmnet(as.matrix(x_training), as.matrix(y_training), alpha=1, intercept = FALSE, lambda = grid,
standardize = FALSE)
y_hat = predict(lasso_cv, s = best_lambda, newx = data.matrix(x_testing))
r_squared = (y_testing - y_hat)^2
lasso_mse = sum(r_squared)/length(r_squared)
return lasso_mse
}
lasso_mse <- function(best_lambda){
scaled_credit <- read.csv("../../data/scaled_credit.csv", stringsAsFactors=FALSE)
load("../../data/training_and_testing.RData")
grid = 10^seq(10, -2, length = 100)
lasso_cv = cv.glmnet(as.matrix(x_training), as.matrix(y_training), alpha=1, intercept = FALSE, lambda = grid,
standardize = FALSE)
y_hat = predict(lasso_cv, s = best_lambda, newx = data.matrix(x_testing))
r_squared = (y_testing - y_hat)^2
lasso_mse = sum(r_squared)/length(r_squared)
return (lasso_mse)
}
lasso_mse(0.01747528)
source("../functions/lasso_mse.R")
context("Test for lasso_mse")
test_that ("lasso_mse works as expected", {
x <- 0.01747528
expect_equal(lasso_mse(x), 0.1811564)
expect_length(lasso_mse(x), 1)
expect_type(lasso_mse(x), 'double')
})
library(testthat)
source("../functions/lasso_mse.R")
context("Test for lasso_mse")
test_that ("lasso_mse works as expected", {
x <- 0.01747528
expect_equal(lasso_mse(x), 0.1811564)
expect_length(lasso_mse(x), 1)
expect_type(lasso_mse(x), 'double')
})
test_that ("lasso_mse works as expected", {
x <- 0.01747528
expect_equal(lasso_mse(x), 0.1811564-3.34e-08)
expect_length(lasso_mse(x), 1)
expect_type(lasso_mse(x), 'double')
})
source("../functions/lasso_mse.R")
context("Test for lasso_mse")
test_that ("lasso_mse works as expected", {
x <- 0.01747528
expect_equal(lasso_mse(x), 0.1811564-3.34e-08)
expect_length(lasso_mse(x), 1)
expect_type(lasso_mse(x), 'double')
})
library(pls)
scaled_credit <- read.csv("../../data/scaled_credit.csv", stringsAsFactors=FALSE)
load("../../data/training_and_testing.RData")
set.seed(200)
plsr_cv = plsr(Balance ~., data = data.frame(training_set), validation = "CV")
plsr_best = which.min(plsr_cv$validation$PRESS)
y_hat = predict(plsr_cv, x_testing, ncomp = plsr_best)
plsr_mse = mean((y_hat - y_testing)^2)
plsr_mse
plsr_best
source("../functions/plsr_mse.R")
context("Test for lasso_mse")
test_that ("plsr_mse works as expected", {
x <- 3
expect_equal(plsr_mse(x), 0.1864991)
expect_length(plsr_mse(x), 1)
expect_type(plsr_mse(x), 'double')
})
source("../functions/plsr_mse.R")
context("Test for lasso_mse")
test_that ("plsr_mse works as expected", {
x <- 3
expect_equal(plsr_mse(x), 0.1864991-3.45e-08)
expect_length(plsr_mse(x), 1)
expect_type(plsr_mse(x), 'double')
})
Credit <- read.csv("../../data/Credit.csv", stringsAsFactors=FALSE)
set.seed( 123)
x<-rnorm( 2000)
y<- .6*x +  sqrt( 1- .6**2)*rnorm( 200)
bplot.xy( x,y, breaks=seq( -3, 3,,15) ,xlim =c(-4,4), ylim =c(-4,4))
install.packages('fields')
library(fields)
bplot.xy( x,y, breaks=seq( -3, 3,,15) ,xlim =c(-4,4), ylim =c(-4,4))
bplot.xy(Credit$Gender, Credit$Balance)
barplot(Credit$Gender, Credit$Balance)
plot(Credit$Gender.category, Credit$Balance)
Credit <- read.csv("../../data/Credit.csv", stringsAsFactors=FALSE)
plot(Credit$Gender.category, Credit$Balance)
boxplot(Credit$Balance~Credit$Gender)
png('../../images/Balance_vs_Credit.png')
boxplot(Credit$Balance~Credit$Gender)
dev.off()
png('../../images/Balance_vs_Student.png')
boxplot(Credit$Balance~Credit$Student)
dev.off()
png('../../images/Balance_vs_Married.png')
boxplot(Credit$Balance~Credit$Married)
dev.off()
png('../../images/Balance_vs_Ethnicity.png')
boxplot(Credit$Balance~Credit$Ethnicity)
dev.off()
pcr_best <- min(pcr_fit$validation$PRESS)
library(pls)
load("../../data/training_and_testing.RData")
x=model.matrix(Balance ~.,training_set)[,-1]
y=training_set$Balance
#fit pcr model
pcr_fit <- pcr(Balance~., data = training_set, scale = FALSE, validation ="CV")
save(pcr_fit, file = "../../data/pcf_fit.RData")
pcr_best <- min(pcr_fit$validation$PRESS)
scaled_credit <- read.csv("../../data/scaled_credit.csv", stringsAsFactors=FALSE)
x_full = model.matrix(Balance~., data = scaled_credit)[,-1]
y_full = scaled_credit$Balance
pcr.fit=pcr(y_full~x_full,scale=FALSE,ncomp=2)
pcr.coef = coef(pcr.fit)
save(pcr_fit, pcr_best, pcr.fit, pcr.coef, file = "../../data/plsr_model.RData")
library(pls)
scaled_credit <- read.csv("../../data/scaled_credit.csv", stringsAsFactors=FALSE)
load("../../data/training_and_testing.RData")
set.seed(200)
plsr_cv = plsr(Balance ~., data = data.frame(training_set), validation = "CV")
summary(plsr_cv)
#cross-validation error plot:
png(file = "../../images/plsr-cv-errors.png")
validationplot(plsr_cv, val.type = "MSEP")
dev.off()
#selecting the best number of components in the model:
plsr_best = which.min(plsr_cv$validation$PRESS)
#test MSE:
y_hat = predict(plsr_cv, x_testing, ncomp = plsr_best)
plsr_mse = mean((y_hat - y_testing)^2)
#refitting:
plsr_refit = plsr(Balance ~., data = data.frame(scaled_credit), ncomp = plsr_best)
plsr_coef = coef(plsr_refit)
# save and output:
save(plsr_cv, plsr_best, plsr_mse, plsr_refit, plsr_coef, file = "../../data/plsr_model.RData")
sink(file = "../../data/plsr-output.txt")
cat("\n Partial Least Squares Regression Model \n")
cat("\n best number of components in model \n")
plsr_best
cat("\n Test MSE \n")
plsr_mse
cat("\n summary of plsr \n")
summary(plsr_refit)
sink()
save(pcr_fit, pcr_best, pcr.fit, pcr.coef, file = "../../data/pcr_model.RData")
load('../../data/pcr_model.RData')
pcr_fit
pcr.coef
pcr_best
pcr_mbest
load("../../data/training_and_testing.RData")
x=model.matrix(Balance ~.,training_set)[,-1]
y=training_set$Balance
pcr_fit <- pcr(Balance~., data = training_set, scale = FALSE, validation ="CV")
save(pcr_fit, file = "../../data/pcf_fit.RData")
pcr_best <- min(pcr_fit$validation$PRESS)
pcr_best
pcr_fit$validation$PRESS
pcr_best <- which.min(pcr_fit$validation$PRESS)
save(pcr_fit, pcr_best, pcr.fit, pcr.coef, file = "../../data/pcr_model.RData")
y_hat = predict(pcr_fit, x, ncomp = pcr_best)
pcr_mse = mean((y_hat - y)^2)
pcr_mse
save(pcr_fit, pcr_best, pcr_mse,pcr.fit, pcr.coef, file = "../../data/pcr_model.RData")
load("../../data/pcr_model.RData")
pcr_mse
save(pcr_fit, pcr_best, pcr_mse,pcr.fit, pcr.coef, file = "../../data/pcr_fit.RData")
library(glmnet)
load("../../data/training_and_testing.RData")
# set lambda value
x=model.matrix(Balance ~.,training_set)[,-1]
y=training_set$Balance
cvfold = 10
grid=10^seq(10,-2,length=100)
ridge_mod <- cv.glmnet(x,y,alpha=0,lambda=grid, nfolds = cvfold)
ridge_mod$lambda.min
coef(ridge_mod, s = "lambda.min")
best_lambda <- ridge_mod$lambda.min
rideg_coef <- coef(ridge_mod, s = "lambda.min")
ridge_coef <- coef(ridge_mod, s = "lambda.min")
y_test = testing_set$Balance
x_test = model.matrix(Balance ~.,testing_set)[,-1]
ridge_mod_pred <- predict(ridge_mod, s=ridge_mod$lambda.min, newx = x_test)
test_mse = mean((ridge_mod_pred - y_test)^2)
scaled_credit <- read.csv("../../data/scaled_credit.csv", stringsAsFactors=FALSE)
x_full = model.matrix(Balance~., data = scaled_credit)[,-1]
y_full = scaled_credit$Balance
out1 = glmnet(x_full, y_full, alpha = 0)
result1 = predict(out1, type = "coefficients", s=ridge_mod$lambda.min)[1:12,]
save(ridge_mod, best_lambda, test_mse, out1, ridge_coef, file = '../../data/all_ridge_mods.RData')
Credit <- read.csv("../../data/Credit.csv", stringsAsFactors=FALSE)
Credit[,]
Credit[,1]
Credit[,-1]
View(Credit[,-1])
Credit_copy <- Credit
temp_credit <- model.matrix(Balance~ ., data = Credit_copy)
temp_credit
View(temp_credit)
new_credit <- cbind(temp_credit[,-c(1,2)], Balance = Credit_copy$Balance)
View(new_credit)
scaled_credit <- scale(new_credit, center = TRUE, scale = TRUE)
head(scaled_credit)
scaled_credit = read.csv("../../data/scaled_credit.csv", stringsAsFactors=FALSE)
head(scaled_credit)
scaled_credit = scaled_credit[,-1]
View(scaled_credit)
